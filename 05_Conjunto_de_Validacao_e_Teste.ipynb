{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "05_Conjunto_de_Validacao_e_Teste.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPS5PWPEd3c1unqDmQJogMD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/julianox5/Exercicios-Programacao-Curso-Machine-Learning-do-GoogleDevelopers/blob/master/05_Conjunto_de_Validacao_e_Teste.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmeKPmPcq6Tf",
        "colab_type": "text"
      },
      "source": [
        "##Conjunto de validação e de teste\n",
        "Os exercícios anteriores da Colab avaliaram o modelo treinado em relação ao conjunto de treinamento, o que não fornece um sinal forte sobre a qualidade do seu modelo. Neste Colab, você experimentará conjuntos de validação e conjuntos de testes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YuMIJ-TerN0i",
        "colab_type": "text"
      },
      "source": [
        "## Objetivos de aprendizado\n",
        "Depois deste Colab, você saberá como fazer o seguinte:\n",
        "* Dividir um conjunto de treinamento em um conjunto menor de treinamento e um conjunto de validação.\n",
        "* Analise deltas entre os resultados do conjunto de treinamento e do conjunto de validação.\n",
        "* Testar o modelo treinado com um conjunto de testes para determinar se seu modelo treinado está se ajustando demais.\n",
        "* Detectar e corrigir um problema de treinamento comum."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vvSuluiwkJk",
        "colab_type": "text"
      },
      "source": [
        "## O conjunto de dados\n",
        "Como no exercício anterior, este exercício usa o conjunto de dados da California Housing para prever o `median_house_value`. Como muitos conjuntos de dados \"famosos\", o California Housing Dataset na verdade consiste em dois conjuntos de dados separados, cada um vivendo em arquivos .csv separados:\n",
        "* O conjunto de treinamento é `california_housing_train.csv`\n",
        "* O conjunto de teste é `california_housing_test.csv`\n",
        "\n",
        "Vamos criar o conjunto de validação dividindo o conjunto de treinamento baixado em duas partes:\n",
        "* Um conjunto de treinamento menor\n",
        "* Um conjunto de validação\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlixNp4JxoUV",
        "colab_type": "text"
      },
      "source": [
        "## Usar a versão correta do TensorFlow\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLIE0Yu6xwMk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vnofg3n3x6KE",
        "colab_type": "text"
      },
      "source": [
        "## Importar modúlos nescessários\n",
        "Essa primeira célula de código importa os módulos necessários e define algumas opções de exibição."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3d7gDJtyMOn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "pd.options.display.max_rows = 10\n",
        "pd.options.display.float_format = \"{:.1f}\".format"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyfsHOa_zO6a",
        "colab_type": "text"
      },
      "source": [
        "##Carregar os conjuntos de dados da Internet\n",
        "Carregando os arquivos .csv separados e criando os dois DataFrames do pandas a seguir:\n",
        "* Conjunto de treinamento `df_treinamento`\n",
        "* Conjunto de teste `df_test`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xMA71EAzorW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_treinamento = pd.read_csv(\"https://download.mlcc.google.com/mledu-datasets/california_housing_train.csv\")\n",
        "df_teste       = pd.read_csv(\"https://download.mlcc.google.com/mledu-datasets/california_housing_test.csv\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WUhuRR806Pm",
        "colab_type": "text"
      },
      "source": [
        "##Escalar os valores dos rótulos\n",
        "Dimensionando o median_house_value. Veja o exercício anterior da Colab para obter detalhes.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKMVLuFi1D31",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_treinamento[\"median_house_value\"] /= 1000.0\n",
        "df_teste[\"median_house_value\"] /= 1000.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQhNDkKQ1hb5",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Carregar as funções para construir e treinar um modelo\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmllTeXN2u_Y",
        "colab_type": "code",
        "outputId": "a419ebf8-d1e1-4d93-bf63-b636716b691b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "def contruir_modelo(tx_aprendizado):\n",
        "\n",
        "  modelo = tf.keras.models.Sequential()\n",
        " \n",
        "  modelo.add(tf.keras.layers.Dense(units=1,\n",
        "                                   input_shape=(1,)))\n",
        "  \n",
        "  modelo.compile(optmizer=tf.keras.optimizers.RMSprop(lr=tx_aprendizado,\n",
        "                                                      loss=\"mean_squared_error\",\n",
        "                                                      metrics=[tf.keras.metrics.RootMeanSquaredError()]))\n",
        "  return modelo\n",
        "\n",
        "def treinar_modelo(modelo, df, recurso, rotulo,epocas, tam_lote=None, div_validacao=0.1):\n",
        "  \n",
        "  history = modelo.fit(x=recurso, y = rotulo,\n",
        "                       epochs = epocas, batch = tam_lote, \n",
        "                       validation_split = div_validacao)\n",
        "  \n",
        "  peso_treinado = modelo.get_weights()[0]\n",
        "  vies_treinado = modelo.get_weights()[1]\n",
        "\n",
        "  epochs = history.epoch\n",
        "\n",
        "  hist = pd.DataFrame(history.history)\n",
        "  rmse = hist[\"root_mean_squared_error\"]\n",
        "\n",
        "  return epochs, rmse, history.history \n",
        "\n",
        "print(\"Ok!\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ok!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52LkyZtz4EZb",
        "colab_type": "text"
      },
      "source": [
        "## Definir Funções de plotagem\n",
        "A função `plot_curva_perda` plota perda versus época para o conjunto de treinamento e o conjunto de validação\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDeVnWLC4eN8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2877b66a-ae6f-4995-956d-9cd2305e10ab"
      },
      "source": [
        "def plot_curva_perda(epochs, set_treinamento, set_validacao):\n",
        "\n",
        "  plt.figure()\n",
        "  plt.xlabel(\"Época\")\n",
        "  plt.ylabel(\"Erro médio quadrático da raiz\")\n",
        "\n",
        "  plt.plot(epochs[1:], set_treinamento, label=\"Perda Treinamento\")\n",
        "  plt.plot(epochs[1:], set_validacao, label=\"Perda validação\")\n",
        "  plt.legend()\n",
        "  # Não vamos traçar a primeira época, já qua perda na primeira época\n",
        "  # geralmente é substancialmente maior que a perda para outras épocas.\n",
        "  lista_fundida = set_treinamento[1:] + set_validacao[1:]\n",
        "\n",
        "  maior_perda = max(lista_fundida)\n",
        "  menor_perda = min(lista_fundida)\n",
        "  delta = maior_perda - menor_perda\n",
        "  print(delta)\n",
        "\n",
        "  topo_eixoY = maior_perda + (delta * 0.05)\n",
        "  fundo_eixoX = menor_perda - (delta * 0.05)\n",
        "\n",
        "  plt.ylim([fundo_eixoX, topo_eixoY])\n",
        "  plt.show()\n",
        "\n",
        "print(\"Definida função para plotar gráfico da curva de perda!\")\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Definida função para plotar gráfico da curva de perda!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPWjdvkGZKda",
        "colab_type": "text"
      },
      "source": [
        "## Tarefa 1: Experiência com a divisão de validação\n",
        "Na célula de código a seguir, você verá uma variável denominada `validacao_div`, que inicializamos em 0,2. A validation_splitvariável especifica a proporção do conjunto de treinamento original que servirá como o conjunto de validação. O conjunto de treinamento original contém 17.000 exemplos. Portanto, um `validacao_div` 0,2 significa que:\n",
        "* 17.000 * 0,2 ~ = 3.400 exemplos se tornarão o conjunto de validação.\n",
        "* 17.000 * 0,8 ~ = 13.600 exemplos se tornarão o novo conjunto de treinamento.\n",
        "\n",
        "O código a seguir cria um modelo, o treina no conjunto de treinamento e avalia o modelo criado em ambos:\n",
        "* Conjunto de treinamento\n",
        "* Conjunto de validacao\n",
        "\n",
        "Se os dados no conjunto de treinamento forem semelhantes aos dados no conjunto de validação, as duas curvas de perda e os valores de perda final deverão ser quase idênticos. No entanto, as curvas de perda e os valores de perda final não são quase idênticos. Hmm, isso é estranho.\n",
        "\n",
        "Experimente com dois ou três valores diferentes de `validacao_div`. Valores diferentes de `validacao_div`correção do problema?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeX7NgPaaVK7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "outputId": "5a4bb2bb-b9cf-4890-b7ec-88021a570615"
      },
      "source": [
        "# Difinindo os hiperparâmetros\n",
        "tx_aprendizado = 0.08\n",
        "epochs = 30 \n",
        "tam_lote = 100\n",
        "\n",
        "#dividindo o conjunto de treinamento original em um conjunto reduzido e um \n",
        "#conjunto de treinamento\n",
        "validacao_div = 0.2\n",
        "\n",
        "#identifica o recurso e o rótulo \n",
        "meu_recurso = \"median_income\" # renda media em um quarteirao específico\n",
        "meu_rotulo  = \"median_house_value\" # o valor medio de uma casa em uma cidade expecífica por bloco\n",
        "# Vamos criar um modelo que prevê o valor da casa com base na renda media do bairro\n",
        "\n",
        "# descartar qualquer versão pré-existente do modelo.\n",
        "meu_modelo = None\n",
        "\n",
        "# invocar as funções para criar e treinar o modelo\n",
        "meu_modelo = contruir_modelo(tx_aprendizado)\n",
        "\n",
        "epochs, rmse, history = treinar_modelo(meu_modelo, df_treinamento, \n",
        "                                       meu_recurso, meu_rotulo, epochs, tam_lote,\n",
        "                                       validacao_div)\n",
        "plot_curva_perda(epochs, history[\"root_mean_squared_error\"], \n",
        "                    history[\"val_root_mean_squared_error\"])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-012923a79614>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# invocar as funções para criar e treinar o modelo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mmeu_modelo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontruir_modelo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtx_aprendizado\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m epochs, rmse, history = treinar_modelo(meu_modelo, df_treinamento, \n",
            "\u001b[0;32m<ipython-input-12-6f7bddd44c3d>\u001b[0m in \u001b[0;36mcontruir_modelo\u001b[0;34m(tx_aprendizado)\u001b[0m\n\u001b[1;32m      8\u001b[0m   modelo.compile(optmizer=tf.keras.optimizers.RMSprop(lr=tx_aprendizado,\n\u001b[1;32m      9\u001b[0m                                                      \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"mean_squared_error\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                                                      metrics=[tf.keras.metrics.RootMeanSquaredError()]))\n\u001b[0m\u001b[1;32m     11\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mmodelo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/rmsprop.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, learning_rate, rho, momentum, epsilon, centered, name, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0mcompatibility\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecommended\u001b[0m \u001b[0mto\u001b[0m \u001b[0muse\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0minstead\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \"\"\"\n\u001b[0;32m--> 133\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRMSprop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_hyper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"learning_rate\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"lr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_hyper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"decay\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial_decay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, **kwargs)\u001b[0m\n\u001b[1;32m    267\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mallowed_kwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         raise TypeError(\"Unexpected keyword argument \"\n\u001b[0;32m--> 269\u001b[0;31m                         \"passed to optimizer: \" + str(k))\n\u001b[0m\u001b[1;32m    270\u001b[0m       \u001b[0;31m# checks that all keyword arguments are non-negative.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Unexpected keyword argument passed to optimizer: loss"
          ]
        }
      ]
    }
  ]
}